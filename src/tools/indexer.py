"""
INDEXADOR DE DOCUMENTOS PARA AZURE AI SEARCH
Script para crear/actualizar √≠ndices y cargar documentos con embeddings vectoriales.
"""

import asyncio
import json
import logging
from pathlib import Path

from langchain_openai import AzureOpenAIEmbeddings

from src.api.core.config import settings
from src.api.search.service import AzureAISearchService

# Configuraci√≥n de Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============================================================================
# CONFIGURACI√ìN DEL MODELO DE EMBEDDINGS
# ============================================================================
embeddings_model = AzureOpenAIEmbeddings(
    azure_deployment=settings.AZURE_OPENAI_EMBEDDING_DEPLOYMENT,
    openai_api_version=settings.AZURE_OPENAI_API_VERSION,
    azure_endpoint=str(settings.AZURE_OPENAI_ENDPOINT),
    api_key=settings.AZURE_OPENAI_API_KEY,
    chunk_size=16,
    max_retries=3,
    timeout=30.0,
)


# ============================================================================
# FUNCI√ìN PRINCIPAL DE INDEXACI√ìN
# ============================================================================
async def index_documents():
    """
    Flujo completo de indexaci√≥n profesional.
    """
    print("=" * 60)
    print("üöÄ INICIANDO PROCESO DE INDEXACI√ìN PROFESIONAL")
    print("=" * 60)

    # 1. Inicializaci√≥n
    search_service = AzureAISearchService()
    data_file = Path("data/documents.json")

    if not data_file.exists():
        print(f"‚ùå Error: No se encontr√≥ el archivo {data_file}")
        return

    # 2. Limpieza y Creaci√≥n de √çndice
    print(f"üìã Preparando √≠ndice: {settings.AZURE_SEARCH_INDEX_NAME}")
    try:
        # Borramos para asegurar que el esquema (id, campos sem√°nticos) sea el nuevo
        print("   üóëÔ∏è Eliminando √≠ndice antiguo para actualizar esquema...")
        try:
            await search_service.index_client.delete_index(
                settings.AZURE_SEARCH_INDEX_NAME
            )
        except Exception:
            pass

        await search_service.create_or_update_index(
            index_name=settings.AZURE_SEARCH_INDEX_NAME,
            vector_dimensions=3072,  # text-embedding-3-large
        )
        print("   ‚úÖ √çndice recreado exitosamente")
    except Exception as e:
        print(f"   ‚ùå Error cr√≠tico en infraestructura: {e}")
        return

    # 3. Carga de datos
    try:
        with open(data_file, "r", encoding="utf-8") as f:
            documents = json.load(f)
        print(f"üìÑ Cargados {len(documents)} documentos desde JSON")
    except Exception as e:
        print(f"‚ùå Error leyendo JSON: {e}")
        return

    # 4. Procesamiento y Embeddings
    print("üîß Generando embeddings y preparando paquetes...")
    processed_docs = []

    for i, doc in enumerate(documents, 1):
        try:
            doc_id = str(doc.get("id", f"doc-{i:03d}"))
            title = doc.get("title", "Sin t√≠tulo")

            # Combinamos t√≠tulo y contenido para un vector m√°s descriptivo
            text_to_embed = f"{title}: {doc.get('content', '')}"

            # Generaci√≥n as√≠ncrona del vector
            vector = await embeddings_model.aembed_query(text_to_embed)

            processed_docs.append(
                {
                    "id": doc_id,
                    "title": title,
                    "content": doc.get("content", ""),
                    "content_vector": vector,
                    "source": doc.get("source", "manual-ingest"),
                    "category": doc.get("category", "General"),
                }
            )

            if i % 5 == 0:
                print(f"   üìä Progreso: {i}/{len(documents)} procesados")

        except Exception as e:
            print(f"   ‚ö†Ô∏è Error en doc {i}: {e}")

    # 5. Subida a Azure
    print(f"‚¨ÜÔ∏è  Subiendo {len(processed_docs)} vectores a Azure AI Search...")
    try:
        stats = await search_service.upsert_vectors(
            index_name=settings.AZURE_SEARCH_INDEX_NAME, vectors=processed_docs
        )

        print("=" * 60)
        print("üìä RESUMEN DE INDEXACI√ìN")
        print("=" * 60)
        print(f"   √âxitos: {stats.get('total_success')}")
        print(f"   Fallos: {stats.get('total_failed')}")
        print("\n‚úÖ Proceso Finalizado")

    except Exception as e:
        print(f"‚ùå Error en la subida: {e}")

    finally:
        await search_service.index_client.close()


if __name__ == "__main__":
    asyncio.run(index_documents())
